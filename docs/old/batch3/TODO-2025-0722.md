# 🎭 RimAI Framework 对话系统 v3.0 实施计划

**基于现有v3.0架构的智能对话系统**

## 📋 项目概述

### 🎯 设计目标
构建一个统一的对话系统，支持多种对话模式和输出格式：
- **对话模式**：1对1 对话（玩家对NPC、NPC对NPC）、多对多 群体对话
- **输出格式**：流式/非流式、JSON/文本、批处理支持
- **场景驱动**：所有对话都基于场景提示词
- **框架集成**：充分利用现有批处理、缓存、配置等特性
- **智能管理**：历史记录、Token控制、内容舍弃、智能总结

### 🏗️ 架构设计
```
RimAI对话系统架构
├── ConversationManager (对话管理器)
│   ├── 1v1 对话
│   │   ├── 玩家 vs NPC
│   │   └── NPC vs NPC
│   └── NvN 多角色对话
├── ScenarioEngine (场景引擎)
│   ├── 场景提示词管理
│   └── 上下文构建
├── OutputProcessor (输出处理器)
│   ├── 流式/非流式切换
│   ├── JSON/文本格式化
│   └── 批处理支持
├── HistoryManager (历史管理器)
│   ├── 对话条目控制
│   ├── Token计数与舍弃
│   └── 智能总结
└── 现有框架集成
    ├── RequestBatcher (批处理)
    ├── ResponseCache (缓存)
    ├── RimAIConfiguration (配置)
    └── LLMManager (LLM管理)
```

---

## 🚀 核心组件设计

### 1. 对话管理器 (ConversationManager)

#### 1.1 统一对话接口
**文件**: `RimAI.Framework/Source/Conversation/ConversationManager.cs`（新建）
```csharp
public static class ConversationManager
{
    /// <summary>
    /// 统一对话API - 支持所有模式和格式
    /// </summary>
    public static async Task<ConversationResult> StartConversationAsync(ConversationRequest request)
    {
        try
        {
            // 1. 场景验证与初始化
            var scenario = await ScenarioEngine.LoadScenarioAsync(request.ScenarioId);
            if (scenario == null)
                throw new ArgumentException($"场景不存在: {request.ScenarioId}");

            // 2. 根据模式选择处理器
            IConversationProcessor processor = request.Mode switch
            {
                ConversationMode.OneToOne => new SingleCharacterProcessor(),
                ConversationMode.MultiParty => new MultiCharacterProcessor(),
                _ => throw new ArgumentException($"不支持的对话模式: {request.Mode}")
            };

            // 3. 历史记录管理
            var history = await HistoryManager.PrepareHistoryAsync(request.SessionId, request.Options);

            // 4. 执行对话
            var context = new ConversationContext
            {
                Request = request,
                Scenario = scenario,
                History = history,
                Options = request.Options ?? new ConversationOptions()
            };

            return await processor.ProcessAsync(context);
        }
        catch (Exception ex)
        {
            RimAILogger.LogError($"对话失败: {ex.Message}");
            return ConversationResult.Failed(ex.Message);
        }
    }
}
```

#### 1.2 对话请求模型
```csharp
public class ConversationRequest
{
    public string SessionId { get; set; } = Guid.NewGuid().ToString();
    public ConversationMode Mode { get; set; } = ConversationMode.OneToOne;
    public ConversationType Type { get; set; } = ConversationType.PlayerToNPC;
    public string ScenarioId { get; set; } // 必需：场景ID
    public string Message { get; set; } // 用户输入或NPC输入
    public string InitiatorId { get; set; } = "Player"; // 发起者ID（玩家或NPC）
    public string TargetId { get; set; } // 目标角色ID（1v1模式）
    public List<string> ParticipantIds { get; set; } = new(); // 多对多模式的参与者
    public ConversationOptions Options { get; set; } = new();
}

public enum ConversationMode
{
    OneToOne,    // 1对1 对话
    MultiParty   // 多对多 群体对话
}

public enum ConversationType
{
    PlayerToNPC,  // 玩家对NPC
    NPCToNPC     // NPC对NPC
}

public class ConversationOptions
{
    // 输出格式控制
    public bool IsStreaming { get; set; } = false;
    public bool OutputAsJson { get; set; } = false;
    public bool EnableBatching { get; set; } = false;
    
    // 历史记录控制
    public int MaxHistoryEntries { get; set; } = 20;
    public int MaxTokens { get; set; } = 4000;
    public bool EnableTokenControl { get; set; } = true;
    public bool EnableSmartSummary { get; set; } = true;
    
    // 对话参数
    public float Temperature { get; set; } = 0.7f;
    public int MaxResponseTokens { get; set; } = 1000;
    public int MaxResponseTokensPerCharacter { get; set; } = 100; // 多角色模式下每个角色的回应限制
    public Dictionary<string, object> CustomParameters { get; set; } = new();
}
```

### 2. 场景引擎 (ScenarioEngine)

#### 2.1 场景管理
**文件**: `RimAI.Framework/Source/Conversation/ScenarioEngine.cs`（新建）
```csharp
public static class ScenarioEngine
{
    private static readonly ResponseCache _cache = ResponseCache.Instance;
    
    public static async Task<ConversationScenario> LoadScenarioAsync(string scenarioId)
    {
        return await _cache.GetOrAddAsync($"scenario:{scenarioId}", 
            async () => await LoadScenarioFromConfig(scenarioId),
            TimeSpan.FromMinutes(30));
    }
    
    public static string BuildContextPrompt(ConversationScenario scenario, ConversationHistory history, ConversationRequest request)
    {
        var builder = new StringBuilder();
        
        // 1. 场景设定
        builder.AppendLine("# 对话场景");
        builder.AppendLine(scenario.Description);
        builder.AppendLine();
        
        // 2. 完整角色设定（多角色模式下所有人都需要了解彼此）
        if (scenario.Characters?.Any() == true)
        {
            builder.AppendLine("# 参与角色");
            foreach (var character in scenario.Characters)
            {
                builder.AppendLine($"• {character.Name}: {character.Description ?? GetCharacterSummary(character.SystemPrompt)}");
            }
            builder.AppendLine();
        }
        
        // 3. 群聊历史记录（优化Token使用）
        if (history?.Messages?.Any() == true)
        {
            builder.AppendLine("# 群聊记录");
            var recentMessages = GetOptimizedHistory(history.Messages, request.Options);
            foreach (var msg in recentMessages)
            {
                var timestamp = msg.Timestamp.ToString("HH:mm");
                builder.AppendLine($"[{timestamp}] {msg.Sender}: {msg.Content}");
            }
            builder.AppendLine();
        }
        
        // 4. 当前输入
        builder.AppendLine("# 最新发言");
        if (request.Type == ConversationType.PlayerToNPC)
        {
            builder.AppendLine($"玩家: {request.Message}");
        }
        else if (request.Type == ConversationType.NPCToNPC)
        {
            builder.AppendLine($"{request.InitiatorId}: {request.Message}");
            if (!string.IsNullOrEmpty(request.TargetId))
            {
                builder.AppendLine($"(回应对象: {request.TargetId})");
            }
        }
        
        return builder.ToString();
    }
    
    /// <summary>
    /// 获取角色简要描述（从SystemPrompt提取关键信息）
    /// </summary>
    private static string GetCharacterSummary(string systemPrompt)
    {
        if (string.IsNullOrEmpty(systemPrompt))
            return "未知角色";
            
        // 提取第一句话作为简要描述
        var firstSentence = systemPrompt.Split('。', '!', '！')[0];
        return firstSentence.Length > 50 ? firstSentence.Substring(0, 47) + "..." : firstSentence;
    }
    
    /// <summary>
    /// 获取优化的历史记录（控制Token数量）
    /// </summary>
    private static List<ConversationMessage> GetOptimizedHistory(List<ConversationMessage> messages, ConversationOptions options)
    {
        if (!messages.Any()) return new List<ConversationMessage>();
        
        var maxHistoryTokens = options.MaxTokens / 3; // 历史记录占总Token的1/3
        var optimizedMessages = new List<ConversationMessage>();
        var currentTokens = 0;
        
        // 从最新消息开始往回选择
        for (int i = messages.Count - 1; i >= 0; i--)
        {
            var msg = messages[i];
            var msgTokens = EstimateTokens($"[{msg.Timestamp:HH:mm}] {msg.Sender}: {msg.Content}");
            
            if (currentTokens + msgTokens <= maxHistoryTokens)
            {
                optimizedMessages.Insert(0, msg);
                currentTokens += msgTokens;
            }
            else
            {
                break;
            }
        }
        
        return optimizedMessages;
    }
}

public class ConversationScenario
{
    public string Id { get; set; }
    public string Name { get; set; }
    public string Description { get; set; } // 场景提示词
    public List<CharacterConfig> Characters { get; set; } = new();
    public ScenarioType Type { get; set; } = ScenarioType.General;
    public Dictionary<string, object> Settings { get; set; } = new();
}

public class CharacterConfig
{
    public string Id { get; set; } // 角色唯一标识
    public string Name { get; set; } // 角色显示名称
    public string Description { get; set; } // 角色描述
    public string SystemPrompt { get; set; } // 角色系统提示词
    public List<string> Tags { get; set; } = new(); // 角色标签
    public bool IsEnabled { get; set; } = true; // 是否启用
    public Dictionary<string, object> Attributes { get; set; } = new(); // 扩展属性
}

public enum ScenarioType
{
    General,        // 通用场景
    Technical,      // 技术讨论
    Creative,       // 创意写作
    Analysis,       // 分析论证
    Roleplay        // 角色扮演
}
```

### 3. 输出处理器 (OutputProcessor)

#### 3.1 多格式输出支持
**文件**: `RimAI.Framework/Source/Conversation/OutputProcessor.cs`（新建）
```csharp
public static class OutputProcessor
{
    public static async Task<ConversationResult> ProcessOutputAsync(
        string rawContent, ConversationContext context)
    {
        var options = context.Options;
        
        // 1. 基础响应构建
        var result = new ConversationResult
        {
            IsSuccess = true,
            SessionId = context.Request.SessionId,
            Timestamp = DateTime.UtcNow,
            Mode = context.Request.Mode
        };
        
        // 2. 格式化处理
        if (options.OutputAsJson)
        {
            result.JsonResponse = FormatAsJson(rawContent, context);
            result.ContentType = "application/json";
        }
        else
        {
            result.TextResponse = rawContent;
            result.ContentType = "text/plain";
        }
        
        // 3. 流式处理
        if (options.IsStreaming)
        {
            result.StreamingSupported = true;
            result.StreamCallback = CreateStreamCallback(context);
        }
        
        // 4. 批处理标记
        if (options.EnableBatching)
        {
            result.BatchId = context.Request.SessionId;
            result.BatchSupported = true;
        }
        
        return result;
    }
    
    private static object FormatAsJson(string content, ConversationContext context)
    {
        return new
        {
            session_id = context.Request.SessionId,
            mode = context.Request.Mode.ToString().ToLower(),
            scenario = context.Scenario.Name,
            timestamp = DateTime.UtcNow.ToString("yyyy-MM-ddTHH:mm:ssZ"),
            response = new
            {
                content = content,
                character_count = content.Length,
                estimated_tokens = EstimateTokens(content)
            },
            metadata = new
            {
                temperature = context.Options.Temperature,
                max_tokens = context.Options.MaxResponseTokens,
                processing_time_ms = 0 // 实际处理时间
            }
        };
    }
    
    private static Func<string, Task> CreateStreamCallback(ConversationContext context)
    {
        return async (chunk) =>
        {
            // 利用现有的流式处理机制
            await RimAIAPI.StreamAsync(chunk, context.Options.CustomParameters);
        };
    }
}
```

### 4. 历史管理器 (HistoryManager)

#### 4.1 智能历史记录管理
**文件**: `RimAI.Framework/Source/Conversation/HistoryManager.cs`（新建）
```csharp
public static class HistoryManager
{
    private static readonly ResponseCache _cache = ResponseCache.Instance;
    
    public static async Task<ConversationHistory> PrepareHistoryAsync(string sessionId, ConversationOptions options)
    {
        var history = await GetHistoryAsync(sessionId);
        
        if (options.EnableTokenControl)
        {
            history = await OptimizeHistoryForTokens(history, options);
        }
        
        if (history.Messages.Count > options.MaxHistoryEntries)
        {
            history = await TrimHistoryWithSummary(history, options);
        }
        
        return history;
    }
    
    public static async Task AddMessageAsync(string sessionId, ConversationMessage message)
    {
        var historyKey = $"conversation_history:{sessionId}";
        var history = await _cache.GetOrAddAsync(historyKey,
            () => Task.FromResult(new ConversationHistory { SessionId = sessionId }),
            TimeSpan.FromHours(4));
            
        history.Messages.Add(message);
        await _cache.SetAsync(historyKey, history, TimeSpan.FromHours(4));
    }
    
    /// <summary>
    /// Token数检查与内容舍弃
    /// </summary>
    private static async Task<ConversationHistory> OptimizeHistoryForTokens(
        ConversationHistory history, ConversationOptions options)
    {
        var currentTokens = history.Messages.Sum(m => EstimateTokens(m.Content));
        
        if (currentTokens <= options.MaxTokens)
            return history;
            
        // 保留最新消息，逐步移除旧消息
        var optimizedHistory = new ConversationHistory { SessionId = history.SessionId };
        var reversedMessages = history.Messages.AsEnumerable().Reverse().ToList();
        var tokenCount = 0;
        
        foreach (var message in reversedMessages)
        {
            var messageTokens = EstimateTokens(message.Content);
            if (tokenCount + messageTokens <= options.MaxTokens)
            {
                optimizedHistory.Messages.Insert(0, message);
                tokenCount += messageTokens;
            }
            else
            {
                break;
            }
        }
        
        return optimizedHistory;
    }
    
    /// <summary>
    /// 智能总结 - 超出条目数时自动总结
    /// </summary>
    private static async Task<ConversationHistory> TrimHistoryWithSummary(
        ConversationHistory history, ConversationOptions options)
    {
        if (!options.EnableSmartSummary || history.Messages.Count <= options.MaxHistoryEntries)
            return history;
            
        // 取出要总结的消息（保留最新的一半）
        var keepCount = options.MaxHistoryEntries / 2;
        var toSummarize = history.Messages.Take(history.Messages.Count - keepCount).ToList();
        var toKeep = history.Messages.Skip(history.Messages.Count - keepCount).ToList();
        
        // 生成总结
        var summaryPrompt = BuildSummaryPrompt(toSummarize);
        var summaryResponse = await RimAIAPI.SendMessageAsync(summaryPrompt, new LLMRequestOptions
        {
            Temperature = 0.3f,
            MaxTokens = 200
        });
        
        // 构建新的历史记录
        var newHistory = new ConversationHistory { SessionId = history.SessionId };
        newHistory.Messages.Add(new ConversationMessage
        {
            Sender = "系统",
            Content = $"[对话总结] {summaryResponse?.Content ?? "无法生成总结"}",
            Timestamp = DateTime.UtcNow,
            MessageType = MessageType.Summary
        });
        newHistory.Messages.AddRange(toKeep);
        
        return newHistory;
    }
    
    private static int EstimateTokens(string text)
    {
        if (string.IsNullOrEmpty(text)) return 0;
        
        // 优化的Token估算（与多角色处理器保持一致）
        var chineseChars = text.Count(c => c >= 0x4e00 && c <= 0x9fff);
        var englishWords = text.Split(' ', StringSplitOptions.RemoveEmptyEntries)
                              .Count(word => word.Any(char.IsLetter));
        var punctuation = text.Count(char.IsPunctuation);
        
        return (int)(chineseChars / 1.5 + englishWords + punctuation * 0.5);
    }
}

public class ConversationHistory
{
    public string SessionId { get; set; }
    public List<ConversationMessage> Messages { get; set; } = new();
    public DateTime CreatedAt { get; set; } = DateTime.UtcNow;
    public DateTime LastUpdated { get; set; } = DateTime.UtcNow;
}

public class ConversationMessage
{
    public string Sender { get; set; }
    public string Content { get; set; }
    public DateTime Timestamp { get; set; } = DateTime.UtcNow;
    public MessageType MessageType { get; set; } = MessageType.User;
    public Dictionary<string, object> Metadata { get; set; } = new();
}

public enum MessageType
{
    User,
    Assistant,
    System,
    Summary
}
```

### 5. 处理器实现

#### 5.1 单角色处理器
**文件**: `RimAI.Framework/Source/Conversation/Processors/SingleCharacterProcessor.cs`（新建）
```csharp
public class SingleCharacterProcessor : IConversationProcessor
{
    public async Task<ConversationResult> ProcessAsync(ConversationContext context)
    {
        // 1. 构建提示词
        var prompt = ScenarioEngine.BuildContextPrompt(
            context.Scenario, context.History, context.Request);
            
        // 2. 根据对话类型选择响应角色
        CharacterConfig responseCharacter = null;
        string senderName = "";
        
        if (context.Request.Type == ConversationType.PlayerToNPC)
        {
            // 玩家对NPC：选择目标NPC或最合适的NPC
            responseCharacter = GetTargetCharacter(context.Scenario, context.Request.TargetId) 
                             ?? SelectBestCharacter(context.Scenario, context.Request.Message);
            senderName = "玩家";
        }
        else if (context.Request.Type == ConversationType.NPCToNPC)
        {
            // NPC对NPC：选择目标NPC
            responseCharacter = GetTargetCharacter(context.Scenario, context.Request.TargetId);
            senderName = context.Request.InitiatorId;
            
            if (responseCharacter == null)
            {
                return ConversationResult.Failed($"目标角色 '{context.Request.TargetId}' 不存在");
            }
        }
        
        // 3. 构建完整提示词
        if (responseCharacter != null)
        {
            var rolePrompt = BuildRolePrompt(responseCharacter, context.Request);
            prompt = $"{rolePrompt}\n\n{prompt}";
        }
        
        // 4. 发送请求
        var llmOptions = new LLMRequestOptions
        {
            Temperature = context.Options.Temperature,
            MaxTokens = context.Options.MaxResponseTokens,
            IsStreaming = context.Options.IsStreaming
        };
        
        var response = await RimAIAPI.SendMessageAsync(prompt, llmOptions);
        
        // 5. 处理响应
        if (response?.IsSuccess == true)
        {
            // 保存到历史记录
            await HistoryManager.AddMessageAsync(context.Request.SessionId, new ConversationMessage
            {
                Sender = senderName,
                Content = context.Request.Message,
                MessageType = context.Request.Type == ConversationType.PlayerToNPC ? MessageType.User : MessageType.Assistant
            });
            
            await HistoryManager.AddMessageAsync(context.Request.SessionId, new ConversationMessage
            {
                Sender = responseCharacter?.Name ?? "系统",
                Content = response.Content,
                MessageType = MessageType.Assistant
            });
            
            return await OutputProcessor.ProcessOutputAsync(response.Content, context);
        }
        
        return ConversationResult.Failed("无法获取响应");
    }
    
    private CharacterConfig GetTargetCharacter(ConversationScenario scenario, string targetId)
    {
        if (string.IsNullOrEmpty(targetId) || scenario.Characters == null)
            return null;
            
        return scenario.Characters.FirstOrDefault(c => 
            c.Name.Equals(targetId, StringComparison.OrdinalIgnoreCase) ||
            c.Id?.Equals(targetId, StringComparison.OrdinalIgnoreCase) == true);
    }
    
    private string BuildRolePrompt(CharacterConfig character, ConversationRequest request)
    {
        var builder = new StringBuilder();
        builder.AppendLine($"你现在扮演角色: {character.Name}");
        builder.AppendLine(character.SystemPrompt);
        
        if (request.Type == ConversationType.NPCToNPC)
        {
            builder.AppendLine($"\n请针对 {request.InitiatorId} 的话语做出合适的回应。");
            builder.AppendLine("保持角色的个性和立场，回应要自然、符合角色设定。");
        }
        
        return builder.ToString();
    }
}
```

#### 5.2 多角色处理器
**文件**: `RimAI.Framework/Source/Conversation/Processors/MultiCharacterProcessor.cs`（新建）
```csharp
public class MultiCharacterProcessor : IConversationProcessor
{
    private static readonly RequestBatcher<CharacterRequest, string> _batcher = 
        new RequestBatcher<CharacterRequest, string>(ProcessBatch, 
            batchSize: 5, windowMs: 200, maxConcurrentBatches: 3);
    
    public async Task<ConversationResult> ProcessAsync(ConversationContext context)
    {
        // 1. 确定参与角色
        var participants = DetermineParticipants(context);
        if (!participants.Any())
        {
            return ConversationResult.Failed("没有可用的参与角色");
        }
        
                 // 2. 构建批处理请求
        var requests = participants.Select(character => new CharacterRequest
        {
            Character = character,
            Context = context,
            Prompt = ScenarioEngine.BuildContextPrompt(context.Scenario, context.History, context.Request)
        }).ToList();
        
        // 3. 并行处理（利用现有批处理系统）
        var responses = await _batcher.AddBatchAsync(requests);
        
        // 4. 组装多角色响应
        var multiResponse = new StringBuilder();
        var characterResponses = new List<CharacterResponse>();
        
        for (int i = 0; i < responses.Count; i++)
        {
            var character = participants[i];
            var content = responses[i];
            
            characterResponses.Add(new CharacterResponse
            {
                CharacterName = character.Name,
                Content = content,
                Timestamp = DateTime.UtcNow
            });
            
            multiResponse.AppendLine($"**{character.Name}**: {content}");
            multiResponse.AppendLine();
        }
        
        // 5. 保存历史记录
        await SaveMultiCharacterHistory(context, characterResponses);
        
        // 6. 处理输出
        var result = await OutputProcessor.ProcessOutputAsync(multiResponse.ToString(), context);
        result.MultiCharacterResponses = characterResponses;
        
        return result;
    }
    
    private static async Task<List<string>> ProcessBatch(List<CharacterRequest> requests)
    {
        var tasks = requests.Select(async request =>
        {
            // 构建角色特定的完整提示词
            var rolePrompt = BuildCharacterRolePrompt(request.Character);
            var fullPrompt = $"{rolePrompt}\n\n{request.Prompt}";
            
            // 严格限制每个角色的回应长度（默认100 Token）
            var maxTokens = request.Context.Options.MaxResponseTokensPerCharacter;
            
            // 验证总提示词长度，防止溢出
            var promptTokens = EstimateTokens(fullPrompt);
            if (promptTokens > request.Context.Options.MaxTokens - maxTokens)
            {
                RimAILogger.LogWarning($"角色 {request.Character.Name} 的提示词过长 ({promptTokens} tokens)，可能影响回应质量");
            }
            
            var response = await RimAIAPI.SendMessageAsync(fullPrompt, new LLMRequestOptions
            {
                Temperature = request.Context.Options.Temperature,
                MaxTokens = maxTokens // 使用严格的Token限制
            });
            
            return response?.Content ?? $"[{request.Character.Name} 无法回应此话题]";
        });
        
        return (await Task.WhenAll(tasks)).ToList();
    }
    
    /// <summary>
    /// 构建角色特定的提示词（包含简洁的指导原则）
    /// </summary>
    private static string BuildCharacterRolePrompt(CharacterConfig character)
    {
        return $@"你现在扮演: {character.Name}
{character.SystemPrompt}

重要指导原则:
- 保持角色个性，回应简洁有力（建议50-80字）
- 针对最新发言做出自然反应
- 考虑其他角色的立场和关系
- 如果不需要发言，可以说""[保持沉默]""或简短表态";
    }
    
    /// <summary>
    /// Token估算工具（优化版）
    /// </summary>
    private static int EstimateTokens(string text)
    {
        if (string.IsNullOrEmpty(text)) return 0;
        
        // 更精确的Token估算
        var chineseChars = text.Count(c => c >= 0x4e00 && c <= 0x9fff);
        var englishWords = text.Split(' ', StringSplitOptions.RemoveEmptyEntries)
                              .Count(word => word.Any(char.IsLetter));
        var punctuation = text.Count(char.IsPunctuation);
        
        // 中文字符约1.5字符/token，英文单词约1 word/token，标点符号约0.5个/token
        return (int)(chineseChars / 1.5 + englishWords + punctuation * 0.5);
    }
}
```

---

## 📊 配置示例

### 场景配置
```json
{
  "Scenarios": {
    "tech_discussion": {
      "Name": "技术讨论",
      "Description": "这是一个技术讨论场景，参与者将从不同角度分析技术问题。请保持专业、客观、有建设性的讨论态度。",
      "Type": "Technical",
             "Characters": [
         {
           "Id": "architect",
           "Name": "架构师",
           "Description": "资深系统架构师，关注可扩展性和性能",
           "SystemPrompt": "你是一位资深系统架构师，擅长从架构设计角度分析问题，关注可扩展性、性能和维护性。",
           "Tags": ["架构", "设计", "性能"]
         },
         {
           "Id": "developer", 
           "Name": "开发工程师",
           "Description": "实战经验丰富的开发工程师，注重实现效率",
           "SystemPrompt": "你是一位实战经验丰富的开发工程师，注重代码实现的可行性和开发效率。",
           "Tags": ["编码", "实现", "效率"]
         },
         {
           "Id": "tester",
           "Name": "测试专家", 
           "Description": "质量保证专家，关注测试策略和风险控制",
           "SystemPrompt": "你是一位测试专家，从质量保证角度考虑问题，关注测试策略和风险控制。",
           "Tags": ["测试", "质量", "风险"]
         }
       ]
    },
    "creative_writing": {
      "Name": "创意写作",
      "Description": "这是一个创意写作场景，参与者将协作创作内容。鼓励创新思维和艺术表达。",
      "Type": "Creative",
             "Characters": [
         {
           "Id": "writer",
           "Name": "作家",
           "SystemPrompt": "你是一位富有想象力的作家，擅长创作引人入胜的故事和生动的描述。",
           "Tags": ["写作", "故事", "创意"]
         },
         {
           "Id": "editor",
           "Name": "编辑",
           "SystemPrompt": "你是一位专业编辑，关注文本的结构、逻辑和语言表达质量。",
           "Tags": ["编辑", "结构", "语言"]
         }
       ]
    }
  }
}
```

---

## 🎯 使用示例

### 1对1 对话示例
```csharp
// 简单的1对1对话
var response = await ConversationManager.StartConversationAsync(new ConversationRequest
{
    Mode = ConversationMode.OneToOne,
    ScenarioId = "tech_discussion",
    Message = "如何优化React应用的性能？",
    Options = new ConversationOptions
    {
        IsStreaming = false,
        OutputAsJson = false,
        MaxHistoryEntries = 10
    }
});

Console.WriteLine(response.TextResponse);
```

### 多对多 对话示例
```csharp
// 多角色群体讨论 - 严格Token控制
var response = await ConversationManager.StartConversationAsync(new ConversationRequest
{
    Mode = ConversationMode.MultiParty,
    ScenarioId = "tech_discussion",
    Message = "微服务架构的优缺点是什么？",
    ParticipantIds = new List<string> { "architect", "developer", "tester" },
    Options = new ConversationOptions
    {
        OutputAsJson = false,
        EnableBatching = true,
        MaxTokens = 3000,
        MaxResponseTokensPerCharacter = 100, // 每个角色最多100 Token
        EnableSmartSummary = true,
        EnableTokenControl = true
    }
});

// 预期输出格式
Console.WriteLine(response.TextResponse);
/* 输出示例：
**架构师**: 微服务架构的主要优势是解耦和独立部署，但会增加系统复杂性和网络开销。需要成熟的DevOps支持。

**开发工程师**: 从开发角度看，微服务确实提高了团队独立性，但调试和测试变得更困难。服务间通信的错误处理是个挑战。

**测试专家**: 测试策略需要重新设计。单元测试相对简单，但集成测试和端到端测试复杂度大幅增加。需要良好的服务模拟机制。
*/
```

### 流式对话示例
```csharp
// 流式输出对话
var response = await ConversationManager.StartConversationAsync(new ConversationRequest
{
    Mode = ConversationMode.OneToOne,
    ScenarioId = "creative_writing",
    Message = "写一个关于AI的科幻短故事",
    Options = new ConversationOptions
    {
        IsStreaming = true,
        MaxResponseTokens = 1500
    }
});

// 流式处理
if (response.StreamingSupported && response.StreamCallback != null)
{
    await response.StreamCallback("开始流式输出...");
}
```

### NPC对NPC 对话示例
```csharp
// NPC之间的对话 - 架构师对开发工程师
var response = await ConversationManager.StartConversationAsync(new ConversationRequest
{
    Mode = ConversationMode.OneToOne,
    Type = ConversationType.NPCToNPC,
    ScenarioId = "tech_discussion",
    InitiatorId = "架构师",
    TargetId = "developer",
    Message = "这个微服务的API设计需要考虑向后兼容性，你觉得应该如何实现版本控制？",
    Options = new ConversationOptions
    {
        OutputAsJson = false,
        MaxHistoryEntries = 15,
        EnableSmartSummary = true
    }
});

Console.WriteLine($"{response.TextResponse}");

// 继续对话 - 开发工程师回应后，测试专家加入
var followUpResponse = await ConversationManager.StartConversationAsync(new ConversationRequest
{
    SessionId = response.SessionId, // 使用同一会话
    Mode = ConversationMode.OneToOne,
    Type = ConversationType.NPCToNPC,
    ScenarioId = "tech_discussion",
    InitiatorId = "开发工程师",
    TargetId = "tester",
    Message = "我们刚讨论了API版本控制的方案，从测试角度你有什么建议？",
    Options = new ConversationOptions
    {
        MaxTokens = 3000,
        EnableTokenControl = true
    }
});
```

### 角色扮演对话示例
```csharp
// 创建一个殖民地角色对话场景
var colonyResponse = await ConversationManager.StartConversationAsync(new ConversationRequest
{
    Mode = ConversationMode.OneToOne,
    Type = ConversationType.NPCToNPC,
    ScenarioId = "colony_life", // 假设有殖民地生活场景
    InitiatorId = "医生萨拉",
    TargetId = "工程师汤姆",
    Message = "汤姆，医疗舱的氧气循环系统出现了问题，你能来看看吗？",
    Options = new ConversationOptions
    {
        Temperature = 0.8f, // 稍高温度增加对话自然度
        MaxResponseTokens = 300
    }
});
```

---

## ⚡ 核心优势

### ✅ 统一架构
- **一套API**: 统一接口支持所有对话模式和输出格式
- **场景驱动**: 所有对话都基于可配置的场景提示词
- **框架集成**: 充分利用现有的批处理、缓存、配置系统

### 🧠 智能管理
- **自动历史优化**: 基于Token数和条目数的智能历史管理
- **智能总结**: 超出限制时自动生成对话总结
- **内容舍弃**: 精确的Token控制和内容优先级管理

### 🚀 高性能
- **并行处理**: 多角色对话利用成熟的批处理系统
- **智能缓存**: 场景、历史记录多层缓存
- **流式支持**: 完整的流式输出能力

### 🔧 灵活配置
- **多输出格式**: 支持文本、JSON、流式、批处理
- **可扩展性**: 场景和角色完全可配置
- **参数控制**: 丰富的对话参数和选项

## 🎛️ 群体对话Token控制最佳实践

### ⚡ **严格Token限制策略**

#### 为什么需要100 Token限制？
1. **成本控制**: 4个角色 × 100 Token = 最多400 Token输出，可预测的费用
2. **用户体验**: 避免某个角色"霸占"对话，保持自然节奏
3. **响应效率**: 短回应更符合真实群体对话的特点
4. **系统稳定**: 防止Token溢出导致的API错误

#### Token分配策略
```csharp
public class ConversationOptions
{
    public int MaxTokens { get; set; } = 4000;                    // 总Token限制
    public int MaxResponseTokensPerCharacter { get; set; } = 100; // 每角色回应限制
    
    // Token分配原则：
    // - 场景描述: ~200 Token
    // - 角色列表: ~150 Token  
    // - 群聊历史: ~1000 Token (动态调整)
    // - 当前输入: ~50 Token
    // - 预留输出: 角色数 × 100 Token
    // - 安全边距: ~500 Token
}
```

### 📱 **群聊记录格式设计**

#### 优化的历史记录格式
```
# 群聊记录
[14:23] 总督: 大家都听好了，以后我们殖民地只要再来那些不三不四的商队，每个人都有主动开火的权力！
[14:24] 安全主管艾伦: 明白，总督！不过我建议制定威胁识别标准，避免误伤。
[14:24] 商人玛丽: 这可能会影响正常贸易...也许先建立黑名单？
[14:25] 医生陈博士: 我担心会导致不必要的冲突和伤亡。
```

#### Token优化技巧
- **时间戳简化**: 使用`HH:mm`格式，节省Token
- **历史记录截断**: 动态计算，保留最重要的上下文
- **角色描述压缩**: 用简洁描述代替完整SystemPrompt

### 🔍 **智能Token管理**

#### 动态历史记录调整
```csharp
private static List<ConversationMessage> GetOptimizedHistory(
    List<ConversationMessage> messages, ConversationOptions options)
{
    var maxHistoryTokens = options.MaxTokens / 3; // 历史记录占1/3
    // 从最新消息向前选择，直到Token限制
    // 保证每个参与角色都有发言记录
}
```

#### Token溢出预防
```csharp
// 验证总提示词长度
var promptTokens = EstimateTokens(fullPrompt);
if (promptTokens > maxTokens - responseTokens)
{
    // 记录警告，但继续执行
    // 系统会自动截断过长的历史记录
}
```

### 📊 **实际Token使用示例**

#### 总督集会场景 Token分析
```
场景描述: 120 Token
参与角色: 80 Token (4个角色 × 20 Token/角色)
群聊历史: 300 Token (约6-8条历史消息)
当前输入: 45 Token (总督的宣告)
角色提示: 160 Token (4个角色 × 40 Token/角色)
安全边距: 295 Token
------------------
总输入: 1000 Token

预期输出: 400 Token (4个角色 × 100 Token/角色)
------------------
总消耗: 1400 Token ✅
```

### 🎯 **最佳实践建议**

1. **角色数量控制**: 建议3-5个角色，超过5个会导致Token紧张
2. **回应长度指导**: 在角色提示中明确要求"简洁有力（50-80字）"
3. **历史记录管理**: 定期清理或总结，避免上下文过长
4. **场景描述优化**: 场景描述应简洁明确，避免冗长背景
5. **Token监控**: 实时监控Token使用情况，及时调整策略

---

*🎯 现代化对话系统，统一接口，智能管理，高性能并行处理！*  
*💡 通过严格的Token控制，确保群体对话既生动又经济高效！* 